# Deploying the API and Web Application to the Cloud

---

## Table of Contents

- [Overview](#overview)
- [Deploying the Flask API and App](#deploying-the-flask-api-and-app)
- [Deploying the Nexjs Flask App](#deploying-the-nexjs-flask-app)

---

## Overview

So far, we have successfully built the machine learning model using Python and Sckit-Learn, a simple API using Flask, a web application using Flask/Python, and another hybrid web application using Nextjs and Flask. In this lesson, we will wrap up this workshop by deploying all these applications to the cloud (which is the goal of this workshop) so users can access them.

By now I believe you have seen the processes that got us here. All those processes are the essential parts of deploying machine learning models to the web. You have to understand what you're building and who you're building for. Upon understanding that you decide the mode of presentation layer you want to work on. If web, you have to "package" the model into an API and web application before finally deploying.

To deploy our Python API and web application, we will use Fly, a cloud platform that allows you to deploy app servers close to your users (using edge computing). The free plan includes up to 3 shared-cpu-1x 256mb virtual machines, 3GB persistent volume storage, and 160GB outbound data transfer. You can use that to get started until you need to scale. You can [read their documentation](https://fly.io/docs/languages-and-frameworks?utm_source=ba-deploy-ml-web-workshop) to learn how to deploy apps in different languages or frameworks.

To deploy the hybrid Nextjs + Flask app, we will use Vercel which will deploy the frontend using SSG and the Flask server as a Python serverless functions. The same should happen if you use similar web deployment platforms like Netlify (however I haven't tested this yet; I'll update this if/when I do).

## Deploying the Flask API and App

I believe you have already created a Fly account and installed flyctl. If you haven't, please see the [prerequisites](../README.md#üõ†-prerequisites-and-installation-guide) section.

Kindly follow the steps below to deploy the API:

1. Ensure you‚Äôre in the root directory of the source code you want to deploy (for me, `/app/flask-api` or `app/flask-app`).
2. Ensure you created a virtual environment before installing the Python libraires used (see the [prerequisites](../README.md#üõ†-prerequisites-and-installation-guide) section if you didn't).
3. Run `pip3 freeze > requirements.txt` to list all the installed packages/version number in the virtual environment inside the `requirements.txt` file.
4. Login into flyctl using the `fly auth login` command.
5. Run the `fly launch` command to launch a new app (this will scan the source code and detect the app type).
6. Enter your app name or leave it blank, and flyctl will generate one.
7. Choose a primary region for deployment (e.g., 'mad' region for Madrid, Spain). Fly uses edge computing to run deployed applications in data centers worldwide. This means you can deploy your apps in [multiple regions](https://fly.io/docs/reference/regions?utm_source=ba-deploy-ml-web-workshop), and your users requests will hit the nearest server to them.
8. A new application will be created in the [Fly dashboard](https://fly.io/dashboard?utm_source=ba-deploy-ml-web-workshop) and flyctl will generate some new files ([`.dockerignore`](https://github.com/BolajiAyodeji/deploy-ml-web-workshop/blob/main/app/flask-api/.dockerignore), [`Procfile`](https://github.com/BolajiAyodeji/deploy-ml-web-workshop/blob/main/app/flask-api/Procfile), and [`fly.toml`](https://github.com/BolajiAyodeji/deploy-ml-web-workshop/blob/main/app/flask-api/fly.toml)) to your source code.
9. Run `fly deploy` to deploy the application (this will take some minutes to finish).
10. Run `fly status` to verify the deployment.

## Deploying the Nexjs Flask App

[!IMPORTANT]
>
> If you deploy this with Vercel, you will run into the [A Serverless Function has exceeded the unzipped maximum size of 250 MB](https://vercel.com/docs/functions/serverless-functions/runtimes#bundle-size-limits) error. This is because, Vercel places restrictions on the maximum uncompressed size of the deployment bundle for functions to ensure that they execute in a timely manner (and most likely in our case, the `scikit-learn` package is increasing the bundle size).

<br />

Lorem

---

<div align="center">

Thank you for coming this far; you've done well üëèüèæ. Please open a new GitHub discussion using the links below and let me know your thoughts about this lesson or any issues you're experiencing.

[Share Feedback](https://github.com/BolajiAyodeji/deploy-ml-web-workshop/discussions/new?category=feedback) | [Ask Question](https://github.com/BolajiAyodeji/deploy-ml-web-workshop/discussions/new?category=q-a)

---

<< [previous lesson](./04.md) | [next lesson](./06.md) >>

</div>

# -*- coding: utf-8 -*-
"""
model_2.ipynb

Automatically generated by Colaboratory.
"""

"""## Install and import the required packages"""

"""## Mount Google Drive and import dataset"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
import pickle
from google.colab import drive
drive.mount("/content/drive")

data = pd.read_csv(
    "/content/drive/MyDrive/Colab Notebooks/deploy-ml-web-workshop/mbpt_dataset_2.csv")

data.head()

data.count()

data['type'].value_counts()

"""## Split train and test (to ensure balanced distribution of data)"""

train_data, test_data = train_test_split(
    data, test_size=0.2, random_state=42, stratify=data.type)

print("\033[93m {}\033[00m" .format('TRAIN DATA \n'), train_data)
print(train_data['type'].value_counts())

print("\033[93m {}\033[00m" .format('TEST DATA \n'),  test_data)
print(test_data['type'].value_counts())

# PS: "\033[93m {}\033[00m" .format('\n AFTER \n') is just a way
# to change the color of the printed string 'TRAIN DATA \n' using ANSI Escape Code.

"""## Tokenize and transform the data"""

vectorizer = TfidfVectorizer(max_features=5000, stop_words="english")

vectorizer.fit(train_data.posts)

train_post = vectorizer.transform(train_data.posts).toarray()

test_post = vectorizer.transform(test_data.posts).toarray()

train_post.shape

target_encoder = LabelEncoder()

train_target = target_encoder.fit_transform(train_data.type)
test_target = target_encoder.fit_transform(test_data.type)

"""## Models testing and selection"""

# Set base Tuple to store the accuracy of each model

models_accuracy = {}

"""#### Logistic Regression"""

model_log = LogisticRegression(max_iter=3000, C=0.5, n_jobs=-1)

model_log.fit(train_post, train_target)

print('Train Classification Report \n ', classification_report(train_target, model_log.predict(
    train_post), zero_division=0, target_names=target_encoder.inverse_transform([i for i in range(16)])))

print('Test Classification Report \n', classification_report(test_target, model_log.predict(
    test_post), zero_division=0, target_names=target_encoder.inverse_transform([i for i in range(16)])))

models_accuracy['Logistic Regression'] = accuracy_score(
    test_target, model_log.predict(test_post))

"""#### Linear Support Vector Classifier"""

model_linear_svc = LinearSVC(C=0.1)

model_linear_svc.fit(train_post, train_target)

print('Train Classification Report \n ', classification_report(train_target, model_linear_svc.predict(
    train_post), zero_division=0, target_names=target_encoder.inverse_transform([i for i in range(16)])))

print('Test Classification Report \n', classification_report(test_target, model_linear_svc.predict(
    test_post), zero_division=0, target_names=target_encoder.inverse_transform([i for i in range(16)])))

models_accuracy['Linear Support Vector Classifier'] = accuracy_score(
    test_target, model_linear_svc.predict(test_post))

"""## Models accuracy summary"""

models_accuracy

accuarcy = pd.DataFrame(models_accuracy.items(), columns=[
                        'Models', 'Test accuracy'])

accuarcy.sort_values(by='Test accuracy', ascending=False,
                     ignore_index=True).style.background_gradient(cmap='Blues')

"""## Save the final model"""

filename = 'model.pkl'

pickle.dump(model_linear_svc, open(filename, 'wb'))

"""### Load and test the saved model"""

loaded_model = pickle.load(open(filename, 'rb'))

message = [
    "This is pretty much the worse movie I have ever watched. It's completely thrash!"]
message = vectorizer.transform(message)

result = loaded_model.predict(message)

print(result, target_encoder.inverse_transform(result))
